{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cac6eee6",
   "metadata": {},
   "source": [
    "初始化环境：\n",
    "- 导包\n",
    "- 加载环境变量\n",
    "- 创建LLM对象"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d3c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from DeepSeekLLM import DeepSeekLLM\n",
    "\n",
    "load_dotenv()\n",
    "llm = DeepSeekLLM(api_key=os.getenv(\"deepseek_api_key\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试llm是否初始化成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9068ba6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = llm.invoke(\"你好！\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28f6364",
   "metadata": {},
   "source": [
    "在 LangChain Chain 中使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0912004f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template=\"回答以下问题：{question}\"\n",
    ")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "print(chain.invoke(\"你是谁？\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41712665",
   "metadata": {},
   "source": [
    "提示词模版"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21810e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='你是一位翻译助手，将English翻译成French。', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "template = \"你是一位翻译助手，将{input_language}翻译成{output_language}。\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "chat_prompt.format_messages(input_language=\"English\", output_language=\"French\", text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59683736",
   "metadata": {},
   "source": [
    "输出解析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faaef81c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac811688",
   "metadata": {},
   "source": [
    "LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a27e28e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['中国', '美国', '日本', '德国', '巴西']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"你是一位助手，生成逗号分隔的列表。\n",
    "用户会传入一个类别，你应该生成该类别中的5个对象，并以逗号分隔的列表返回。\n",
    "只返回逗号分隔的列表，不要返回其他内容。\"\"\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "chain = LLMChain(\n",
    "    llm=llm, # 使用DeepSeekLLM\n",
    "    prompt=chat_prompt,\n",
    "    output_parser=CommaSeparatedListOutputParser()\n",
    ")\n",
    "chain.run(\"国家\")\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
